{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.11 64-bit ('tf-env': conda)"},"language_info":{"name":"python","version":"3.8.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"ac6014c2536665826734fe3568d3f6aa59e00529cbfaf1baeb55fcf03ee1c502"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":2,"source":["!wget https://pjreddie.com/media/files/yolov3.weights"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-08-14 17:35:22--  https://pjreddie.com/media/files/yolov3.weights\n","Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 248007048 (237M) [application/octet-stream]\n","Saving to: ‘yolov3.weights.1’\n","\n","yolov3.weights.1    100%[===================>] 236.52M  23.3MB/s    in 11s     \n","\n","2021-08-14 17:35:34 (21.7 MB/s) - ‘yolov3.weights.1’ saved [248007048/248007048]\n","\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:22.090951Z","iopub.execute_input":"2021-08-14T17:35:22.091510Z","iopub.status.idle":"2021-08-14T17:35:34.572678Z","shell.execute_reply.started":"2021-08-14T17:35:22.091454Z","shell.execute_reply":"2021-08-14T17:35:34.571350Z"},"trusted":true}},{"cell_type":"code","execution_count":2,"source":["# This Python 3 environment comes with many helpful analytics libraries installed\r\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\r\n","# For example, here's several helpful packages to load\r\n","\r\n","import numpy as np # linear algebra\r\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n","\r\n","# Input data files are available in the read-only \"../input/\" directory\r\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\r\n","\r\n","import os\r\n","import cv2\r\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\r\n","#     for filename in filenames:\r\n","#         print(os.path.join(dirname, filename))\r\n","\r\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \r\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"outputs":[],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-14T17:35:34.574633Z","iopub.execute_input":"2021-08-14T17:35:34.574958Z","iopub.status.idle":"2021-08-14T17:35:34.808939Z","shell.execute_reply.started":"2021-08-14T17:35:34.574922Z","shell.execute_reply":"2021-08-14T17:35:34.807905Z"},"trusted":true}},{"cell_type":"code","execution_count":4,"source":["IMAGE_SIZE = 768\r\n","IMAGE_WIDTH = IMAGE_SIZE\r\n","IMAGE_HEIGHT = IMAGE_SIZE\r\n","\r\n","YOLO_MAX_BOXES = 100\r\n","YOLO_IOU_THRESHOLD = 0.5\r\n","YOLO_SCORE_THRESHOLD = 0.5\r\n","# define the anchors\r\n","#anchors = [[[116,90], [156,198], [373,326]], [[30,61], [62,45], [59,119]], [[10,13], [16,30], [33,23]]]\r\n","\r\n","# define the probability threshold for detected objects\r\n","#class_threshold = 0.6\r\n","\r\n","# YoloV3 outputs\r\n","#FEATURE_SHAPE = [(24, 24), (48, 48), (96, 96)]\r\n","\r\n","KAGGLE_INPUT = '/kaggle/input/airbus-ship-detection-train-set-70/'\r\n","KAGGLE_INPUT_IMAGE_TRAIN = '../input/airbus-ship-detection-train-set-70/train_v3/train_v3/Images/'\r\n","\r\n","N_CLASSES = 1\r\n","# 3 слоя, в одной ячейке: x,y,w,h,obj,class\r\n","CELL_FEATURE_SIZE = (5 + N_CLASSES) * 3\r\n","\r\n","YOLO_ANCHORS = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\r\n","                         (59, 119), (116, 90), (156, 198), (373, 326)],\r\n","                        np.float32) / 416\r\n","YOLO_ANCHOR_MASKS = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:34.811420Z","iopub.execute_input":"2021-08-14T17:35:34.811875Z","iopub.status.idle":"2021-08-14T17:35:34.820021Z","shell.execute_reply.started":"2021-08-14T17:35:34.811826Z","shell.execute_reply":"2021-08-14T17:35:34.819142Z"},"trusted":true}},{"cell_type":"code","execution_count":5,"source":["def rle2bbox(rle, shape):\r\n","    \r\n","    a = np.fromiter(rle.split(), dtype=np.uint)\r\n","    a = a.reshape((-1, 2))\r\n","    a[:,0] -= 1\r\n","    \r\n","    y0 = a[:,0] % shape[0]\r\n","    y1 = y0 + a[:,1]\r\n","    if np.any(y1 > shape[0]):\r\n","        y0 = 0\r\n","        y1 = shape[0]\r\n","    else:\r\n","        y0 = np.min(y0)\r\n","        y1 = np.max(y1)\r\n","    \r\n","    x0 = a[:,0] // shape[0]\r\n","    x1 = (a[:,0] + a[:,1]) // shape[0]\r\n","    x0 = np.min(x0)\r\n","    x1 = np.max(x1)\r\n","    \r\n","    if x1 > shape[1]:\r\n","        raise ValueError(\"invalid RLE or image dimensions: x1=%d > shape[1]=%d\" % (\r\n","            x1, shape[1]\r\n","        ))\r\n","        \r\n","    return [x0/IMAGE_WIDTH, y0/IMAGE_HEIGHT, x1/IMAGE_WIDTH, y1/IMAGE_HEIGHT]\r\n","\r\n","#     xc = (x0+x1)/(2*IMAGE_WIDTH)\r\n","#     yc = (y0+y1)/(2*IMAGE_HEIGHT)\r\n","#     w = np.abs(x1-x0)/IMAGE_WIDTH\r\n","#     h = np.abs(y1-y0)/IMAGE_HEIGHT\r\n","#     return [xc, yc, h, w]"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:34.821949Z","iopub.execute_input":"2021-08-14T17:35:34.822316Z","iopub.status.idle":"2021-08-14T17:35:34.841234Z","shell.execute_reply.started":"2021-08-14T17:35:34.822285Z","shell.execute_reply":"2021-08-14T17:35:34.840021Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# TODO: переделать под наш старый формат, см. rle2bbox\r\n","def load_boxes():\r\n","    boxes = dict()\r\n","    for path in glob('../input/fish-json/*.json'):\r\n","        label = os.path.basename(path).split('_', 1)[0]\r\n","        with open(path) as src:\r\n","            boxes[label] = json.load(src)\r\n","            for annotation in boxes[label]:\r\n","                basename = os.path.basename(annotation['filename'])\r\n","                annotation['filename'] = os.path.join(TRAIN_PREFIX, label.upper(), basename)\r\n","            for annotation in boxes[label]:\r\n","                for rect in annotation['annotations']:\r\n","                    rect['x'] += rect['width'] / 2\r\n","                    rect['y'] += rect['height'] / 2\r\n","    return boxes"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["def aggregate_bb(x):    \r\n","    if len(x) == 1 and x.iloc[0] is np.NaN:\r\n","        return list()\r\n","    \r\n","    bb = list(x)\r\n","#     for item in x:\r\n","# #         item_bb = []\r\n","# #         item_bb = {\r\n","# #             'x': item[0],\r\n","# #             'y': item[1],\r\n","# #             'height': item[2],\r\n","# #             'width': item[3]\r\n","# #         }\r\n","#         bb.append(item)\r\n","    return bb"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:34.842835Z","iopub.execute_input":"2021-08-14T17:35:34.843176Z","iopub.status.idle":"2021-08-14T17:35:34.853158Z","shell.execute_reply.started":"2021-08-14T17:35:34.843144Z","shell.execute_reply":"2021-08-14T17:35:34.851938Z"},"trusted":true}},{"cell_type":"code","execution_count":7,"source":["ships = pd.read_csv(KAGGLE_INPUT + \"train_ship_segmentations_v3.csv\")\r\n","ships[\"Boundingbox\"] = ships[\"EncodedPixels\"].apply(lambda x:rle2bbox(x,(IMAGE_SIZE,IMAGE_SIZE)) if isinstance(x,str) else np.NaN)\r\n","\r\n","ships_new = ships.groupby(ships['ImageId']).aggregate({'Boundingbox': aggregate_bb, 'ImageId': 'first'})\r\n","# ships_without_nans = ships_new[ships_new['Boundingbox'] is not np.NaN]\r\n","# ships_without_nans = ships_new[len(ships_new['Boundingbox']) > 0]\r\n","# ships_without_nans = ships_new.mask(lambda x: len(x['Boundingbox']) > 0)\r\n","ships_without_nans = ships_new[ships_new.apply(lambda x: len(x['Boundingbox']) > 0, axis=1)]\r\n","ships_without_nans"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     Boundingbox  \\\n","ImageId                                                            \n","000155de5.jpg  [[0.4479166666666667, 0.60546875, 0.58203125, ...   \n","000194a2d.jpg  [[0.6106770833333334, 0.3736979166666667, 0.63...   \n","0002756f7.jpg  [[0.43359375, 0.046875, 0.4557291666666667, 0....   \n","000532683.jpg  [[0.77734375, 0.5989583333333334, 0.78515625, ...   \n","00053c6ba.jpg  [[0.9583333333333334, 0.16145833333333334, 0.9...   \n","...                                                          ...   \n","fff77c602.jpg  [[0.22526041666666666, 0.059895833333333336, 0...   \n","fff909871.jpg  [[0.7473958333333334, 0.2747395833333333, 0.79...   \n","fffcb6464.jpg  [[0.3776041666666667, 0.07161458333333333, 0.4...   \n","fffd924fb.jpg  [[0.18619791666666666, 0.2421875, 0.1927083333...   \n","fffdd2377.jpg  [[0.5651041666666666, 0.3528645833333333, 0.78...   \n","\n","                     ImageId  \n","ImageId                       \n","000155de5.jpg  000155de5.jpg  \n","000194a2d.jpg  000194a2d.jpg  \n","0002756f7.jpg  0002756f7.jpg  \n","000532683.jpg  000532683.jpg  \n","00053c6ba.jpg  00053c6ba.jpg  \n","...                      ...  \n","fff77c602.jpg  fff77c602.jpg  \n","fff909871.jpg  fff909871.jpg  \n","fffcb6464.jpg  fffcb6464.jpg  \n","fffd924fb.jpg  fffd924fb.jpg  \n","fffdd2377.jpg  fffdd2377.jpg  \n","\n","[29806 rows x 2 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Boundingbox</th>\n","      <th>ImageId</th>\n","    </tr>\n","    <tr>\n","      <th>ImageId</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>000155de5.jpg</th>\n","      <td>[[0.4479166666666667, 0.60546875, 0.58203125, ...</td>\n","      <td>000155de5.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>000194a2d.jpg</th>\n","      <td>[[0.6106770833333334, 0.3736979166666667, 0.63...</td>\n","      <td>000194a2d.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>0002756f7.jpg</th>\n","      <td>[[0.43359375, 0.046875, 0.4557291666666667, 0....</td>\n","      <td>0002756f7.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>000532683.jpg</th>\n","      <td>[[0.77734375, 0.5989583333333334, 0.78515625, ...</td>\n","      <td>000532683.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>00053c6ba.jpg</th>\n","      <td>[[0.9583333333333334, 0.16145833333333334, 0.9...</td>\n","      <td>00053c6ba.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>fff77c602.jpg</th>\n","      <td>[[0.22526041666666666, 0.059895833333333336, 0...</td>\n","      <td>fff77c602.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>fff909871.jpg</th>\n","      <td>[[0.7473958333333334, 0.2747395833333333, 0.79...</td>\n","      <td>fff909871.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>fffcb6464.jpg</th>\n","      <td>[[0.3776041666666667, 0.07161458333333333, 0.4...</td>\n","      <td>fffcb6464.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>fffd924fb.jpg</th>\n","      <td>[[0.18619791666666666, 0.2421875, 0.1927083333...</td>\n","      <td>fffd924fb.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>fffdd2377.jpg</th>\n","      <td>[[0.5651041666666666, 0.3528645833333333, 0.78...</td>\n","      <td>fffdd2377.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>29806 rows × 2 columns</p>\n","</div>"]},"metadata":{},"execution_count":7}],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:34.854601Z","iopub.execute_input":"2021-08-14T17:35:34.855025Z","iopub.status.idle":"2021-08-14T17:35:47.389744Z","shell.execute_reply.started":"2021-08-14T17:35:34.854991Z","shell.execute_reply":"2021-08-14T17:35:47.388909Z"},"trusted":true}},{"cell_type":"code","execution_count":8,"source":["# based on https://github.com/experiencor/keras-yolo3\r\n","import struct\r\n","import numpy as np\r\n","import tensorflow as tf\r\n","from tensorflow.keras.layers import Conv2D\r\n","from tensorflow.keras.layers import Input\r\n","from tensorflow.keras.layers import BatchNormalization\r\n","from tensorflow.keras.layers import LeakyReLU\r\n","from tensorflow.keras.layers import ZeroPadding2D\r\n","from tensorflow.keras.layers import UpSampling2D\r\n","from tensorflow.keras.layers import add, concatenate\r\n","from tensorflow.keras.models import Model\r\n","\r\n","from tensorflow.keras.applications import vgg16\r\n","\r\n","from tensorflow.keras.losses import (\r\n","    binary_crossentropy,\r\n","    sparse_categorical_crossentropy\r\n",")\r\n","\r\n","\r\n","\r\n","def _meshgrid(n_a, n_b):\r\n","\r\n","    return [\r\n","        tf.reshape(tf.tile(tf.range(n_a), [n_b]), (n_b, n_a)),\r\n","        tf.reshape(tf.repeat(tf.range(n_b), n_a), (n_b, n_a))\r\n","    ]\r\n","\r\n","\r\n","def yolo_boxes(pred, anchors, classes):\r\n","    # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))\r\n","    grid_size = tf.shape(pred)[1:3]\r\n","    box_xy, box_wh, objectness, class_probs = tf.split(\r\n","        pred, (2, 2, 1, classes), axis=-1)\r\n","\r\n","    box_xy = tf.sigmoid(box_xy)\r\n","    objectness = tf.sigmoid(objectness)\r\n","    class_probs = tf.sigmoid(class_probs)\r\n","    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss\r\n","\r\n","    # !!! grid[x][y] == (y, x)\r\n","    grid = _meshgrid(grid_size[1],grid_size[0])\r\n","    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\r\n","\r\n","    box_xy = (box_xy + tf.cast(grid, tf.float32)) / \\\r\n","        tf.cast(grid_size, tf.float32)\r\n","    box_wh = tf.exp(box_wh) * anchors\r\n","\r\n","    box_x1y1 = box_xy - box_wh / 2\r\n","    box_x2y2 = box_xy + box_wh / 2\r\n","    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\r\n","\r\n","    return bbox, objectness, class_probs, pred_box\r\n","\r\n","\r\n","def yolo_nms(outputs, anchors, masks, classes):\r\n","    # boxes, conf, type\r\n","    b, c, t = [], [], []\r\n","\r\n","    for o in outputs:\r\n","        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\r\n","        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\r\n","        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\r\n","\r\n","    bbox = tf.concat(b, axis=1)\r\n","    confidence = tf.concat(c, axis=1)\r\n","    class_probs = tf.concat(t, axis=1)\r\n","\r\n","    scores = confidence * class_probs\r\n","\r\n","    dscores = tf.squeeze(scores, axis=0)\r\n","    scores = tf.reduce_max(dscores,[1])\r\n","    bbox = tf.reshape(bbox,(-1,4))\r\n","    classes = tf.argmax(dscores,1)\r\n","    selected_indices, selected_scores = tf.image.non_max_suppression_with_scores(\r\n","        boxes=bbox,\r\n","        scores=scores,\r\n","        max_output_size=YOLO_MAX_BOXES,\r\n","        iou_threshold=YOLO_IOU_THRESHOLD,\r\n","        score_threshold=YOLO_SCORE_THRESHOLD,\r\n","        soft_nms_sigma=0.5\r\n","    )\r\n","    \r\n","    num_valid_nms_boxes = tf.shape(selected_indices)[0]\r\n","\r\n","    selected_indices = tf.concat([selected_indices,tf.zeros(YOLO_MAX_BOXES-num_valid_nms_boxes, tf.int32)], 0)\r\n","    selected_scores = tf.concat([selected_scores,tf.zeros(YOLO_MAX_BOXES-num_valid_nms_boxes,tf.float32)], -1)\r\n","\r\n","    boxes=tf.gather(bbox, selected_indices)\r\n","    boxes = tf.expand_dims(boxes, axis=0)\r\n","    scores=selected_scores\r\n","    scores = tf.expand_dims(scores, axis=0)\r\n","    classes = tf.gather(classes,selected_indices)\r\n","    classes = tf.expand_dims(classes, axis=0)\r\n","    valid_detections=num_valid_nms_boxes\r\n","    valid_detections = tf.expand_dims(valid_detections, axis=0)\r\n","\r\n","    return boxes, scores, classes, valid_detections\r\n","\r\n"," \r\n","def _conv_block(inp, convs, skip=True):\r\n","    x = inp\r\n","    count = 0\r\n","    for conv in convs:\r\n","        if count == (len(convs) - 2) and skip:\r\n","            skip_connection = x\r\n","        count += 1\r\n","        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\r\n","        x = Conv2D(conv['filter'],\r\n","                   conv['kernel'],\r\n","                   strides=conv['stride'],\r\n","                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\r\n","                   name='conv_' + str(conv['layer_idx']),\r\n","                   use_bias=False if conv['bnorm'] else True)(x)\r\n","        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\r\n","        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\r\n","    return add([skip_connection, x]) if skip else x\r\n"," \r\n","def make_yolov3_model():\r\n","    input_image = Input(shape=(None, None, 3))\r\n","    # Layer  0 => 4\r\n","    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\r\n","                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\r\n","                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\r\n","                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\r\n","    # Layer  5 => 8\r\n","    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\r\n","                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\r\n","                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\r\n","    # Layer  9 => 11\r\n","    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\r\n","                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\r\n","    # Layer 12 => 15\r\n","    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\r\n","                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\r\n","                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\r\n","    # Layer 16 => 36\r\n","    for i in range(7):\r\n","        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\r\n","                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\r\n","    skip_36 = x\r\n","    # Layer 37 => 40\r\n","    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\r\n","                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\r\n","                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\r\n","    # Layer 41 => 61\r\n","    for i in range(7):\r\n","        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\r\n","                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\r\n","    skip_61 = x\r\n","    # Layer 62 => 65\r\n","    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\r\n","                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\r\n","                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\r\n","    # Layer 66 => 74\r\n","    for i in range(3):\r\n","        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\r\n","                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\r\n","    # Layer 75 => 79\r\n","    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\r\n","                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\r\n","                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\r\n","                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\r\n","                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\r\n","    # Layer 80 => 82\r\n","    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\r\n","                              {'filter':  CELL_FEATURE_SIZE, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\r\n","    # Layer 83 => 86\r\n","    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\r\n","    x = UpSampling2D(2)(x)\r\n","    x = concatenate([x, skip_61])\r\n","    # Layer 87 => 91\r\n","    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\r\n","                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\r\n","                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\r\n","                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\r\n","                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\r\n","    # Layer 92 => 94\r\n","    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\r\n","                              {'filter': CELL_FEATURE_SIZE, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\r\n","    # Layer 95 => 98\r\n","    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\r\n","    x = UpSampling2D(2)(x)\r\n","    x = concatenate([x, skip_36])\r\n","    # Layer 99 => 106\r\n","    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\r\n","                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\r\n","                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\r\n","                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\r\n","                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\r\n","                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\r\n","                               {'filter': CELL_FEATURE_SIZE, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\r\n","    \r\n","    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\r\n","    return model\r\n"," \r\n","class WeightReader:\r\n","    def __init__(self, weight_file):\r\n","        with open(weight_file, 'rb') as w_f:\r\n","            major,    = struct.unpack('i', w_f.read(4))\r\n","            minor,    = struct.unpack('i', w_f.read(4))\r\n","            revision, = struct.unpack('i', w_f.read(4))\r\n","            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\r\n","                w_f.read(8)\r\n","            else:\r\n","                w_f.read(4)\r\n","            transpose = (major > 1000) or (minor > 1000)\r\n","            binary = w_f.read()\r\n","        self.offset = 0\r\n","        self.all_weights = np.frombuffer(binary, dtype='float32')\r\n"," \r\n","    def read_bytes(self, size):\r\n","        self.offset = self.offset + size\r\n","        return self.all_weights[self.offset-size:self.offset]\r\n"," \r\n","    def load_weights(self, model):\r\n","        for i in range(106):\r\n","            try:\r\n","                conv_layer = model.get_layer('conv_' + str(i))\r\n","                print(\"loading weights of convolution #\" + str(i))\r\n","                if i not in [81, 93, 105]:\r\n","                    norm_layer = model.get_layer('bnorm_' + str(i))\r\n","                    size = np.prod(norm_layer.get_weights()[0].shape)\r\n","                    beta  = self.read_bytes(size) # bias\r\n","                    gamma = self.read_bytes(size) # scale\r\n","                    mean  = self.read_bytes(size) # mean\r\n","                    var   = self.read_bytes(size) # variance\r\n","                    weights = norm_layer.set_weights([gamma, beta, mean, var])\r\n","                if len(conv_layer.get_weights()) > 1:\r\n","                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\r\n","                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\r\n","                    if i in [81, 93, 105]:\r\n","                        bias = bias[:CELL_FEATURE_SIZE]\r\n","                        kernel = kernel[..., :CELL_FEATURE_SIZE]\r\n","                        \r\n","                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\r\n","                    kernel = kernel.transpose([2,3,1,0])\r\n","                    conv_layer.set_weights([kernel, bias])\r\n","#                     if i in [81, 93, 105]:\r\n","#                         print(\"AAAAAAAA\"*5, bias.shape, kernel.shape)\r\n","                else:\r\n","                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\r\n","                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\r\n","                    kernel = kernel.transpose([2,3,1,0])\r\n","                    conv_layer.set_weights([kernel])\r\n","                    \r\n","                if i in [80, 81, 92, 93, 99, 100, 101, 102, 103, 104, 105]:\r\n","                    conv_layer.trainable = True\r\n","                else:\r\n","                    conv_layer.trainable = False\r\n","            except ValueError:\r\n","                print(\"no convolution #\" + str(i))\r\n"," \r\n","    def reset(self):\r\n","        self.offset = 0\r\n"," \r\n","# define the model\r\n","model = make_yolov3_model()\r\n","# load the model weights\r\n","weight_reader = WeightReader('yolov3.weights')\r\n","# set the model weights into the model\r\n","weight_reader.load_weights(model)\r\n","# save the model to file\r\n","model.save('model.h5')"],"outputs":[{"output_type":"stream","name":"stdout","text":["loading weights of convolution #0\n","loading weights of convolution #1\n","loading weights of convolution #2\n","loading weights of convolution #3\n","no convolution #4\n","loading weights of convolution #5\n","loading weights of convolution #6\n","loading weights of convolution #7\n","no convolution #8\n","loading weights of convolution #9\n","loading weights of convolution #10\n","no convolution #11\n","loading weights of convolution #12\n","loading weights of convolution #13\n","loading weights of convolution #14\n","no convolution #15\n","loading weights of convolution #16\n","loading weights of convolution #17\n","no convolution #18\n","loading weights of convolution #19\n","loading weights of convolution #20\n","no convolution #21\n","loading weights of convolution #22\n","loading weights of convolution #23\n","no convolution #24\n","loading weights of convolution #25\n","loading weights of convolution #26\n","no convolution #27\n","loading weights of convolution #28\n","loading weights of convolution #29\n","no convolution #30\n","loading weights of convolution #31\n","loading weights of convolution #32\n","no convolution #33\n","loading weights of convolution #34\n","loading weights of convolution #35\n","no convolution #36\n","loading weights of convolution #37\n","loading weights of convolution #38\n","loading weights of convolution #39\n","no convolution #40\n","loading weights of convolution #41\n","loading weights of convolution #42\n","no convolution #43\n","loading weights of convolution #44\n","loading weights of convolution #45\n","no convolution #46\n","loading weights of convolution #47\n","loading weights of convolution #48\n","no convolution #49\n","loading weights of convolution #50\n","loading weights of convolution #51\n","no convolution #52\n","loading weights of convolution #53\n","loading weights of convolution #54\n","no convolution #55\n","loading weights of convolution #56\n","loading weights of convolution #57\n","no convolution #58\n","loading weights of convolution #59\n","loading weights of convolution #60\n","no convolution #61\n","loading weights of convolution #62\n","loading weights of convolution #63\n","loading weights of convolution #64\n","no convolution #65\n","loading weights of convolution #66\n","loading weights of convolution #67\n","no convolution #68\n","loading weights of convolution #69\n","loading weights of convolution #70\n","no convolution #71\n","loading weights of convolution #72\n","loading weights of convolution #73\n","no convolution #74\n","loading weights of convolution #75\n","loading weights of convolution #76\n","loading weights of convolution #77\n","loading weights of convolution #78\n","loading weights of convolution #79\n","loading weights of convolution #80\n","loading weights of convolution #81\n","no convolution #81\n","no convolution #82\n","no convolution #83\n","loading weights of convolution #84\n","no convolution #85\n","no convolution #86\n","loading weights of convolution #87\n","loading weights of convolution #88\n","loading weights of convolution #89\n","loading weights of convolution #90\n","loading weights of convolution #91\n","loading weights of convolution #92\n","loading weights of convolution #93\n","no convolution #93\n","no convolution #94\n","no convolution #95\n","loading weights of convolution #96\n","no convolution #97\n","no convolution #98\n","loading weights of convolution #99\n","loading weights of convolution #100\n","loading weights of convolution #101\n","loading weights of convolution #102\n","loading weights of convolution #103\n","loading weights of convolution #104\n","loading weights of convolution #105\n","no convolution #105\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:47.391445Z","iopub.execute_input":"2021-08-14T17:35:47.391962Z","iopub.status.idle":"2021-08-14T17:35:58.749397Z","shell.execute_reply.started":"2021-08-14T17:35:47.391916Z","shell.execute_reply":"2021-08-14T17:35:58.747410Z"},"trusted":true}},{"cell_type":"code","execution_count":9,"source":["def load_img(file_name, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)):\r\n","#     file_name = sub_df.iloc[0].loc['ImageId']\r\n","    img = cv2.imread(KAGGLE_INPUT_IMAGE_TRAIN + file_name, cv2.IMREAD_COLOR)[...,::-1]\r\n","#     img = cv2.imread(path, cv2.IMREAD_COLOR)[...,::-1]\r\n","    img_shape = img.shape\r\n","    img_resized = cv2.resize(img, target_size)\r\n","    return img_shape, img_resized.astype(np.float32) / 255.0 #vgg16.preprocess_input(img_resized.astype(np.float32))\r\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:58.754124Z","iopub.execute_input":"2021-08-14T17:35:58.754616Z","iopub.status.idle":"2021-08-14T17:35:58.772368Z","shell.execute_reply.started":"2021-08-14T17:35:58.754564Z","shell.execute_reply":"2021-08-14T17:35:58.764617Z"},"trusted":true}},{"cell_type":"code","execution_count":10,"source":["\r\n","\r\n","# def parse_tfrecord(tfrecord, class_table, size):\r\n","#     x = tf.io.parse_single_example(tfrecord, IMAGE_FEATURE_MAP)\r\n","#     x_train = tf.image.decode_jpeg(x['image/encoded'], channels=3)\r\n","#     x_train = tf.image.resize(x_train, (size, size))\r\n","\r\n","#     class_text = tf.sparse.to_dense(\r\n","#         x['image/object/class/text'], default_value='')\r\n","#     labels = tf.cast(class_table.lookup(class_text), tf.float32)\r\n","#     y_train = tf.stack([tf.sparse.to_dense(x['image/object/bbox/xmin']),\r\n","#                         tf.sparse.to_dense(x['image/object/bbox/ymin']),\r\n","#                         tf.sparse.to_dense(x['image/object/bbox/xmax']),\r\n","#                         tf.sparse.to_dense(x['image/object/bbox/ymax']),\r\n","#                         labels], axis=1)\r\n","\r\n","#     paddings = [[0, YOLO_MAX_BOXES - tf.shape(y_train)[0]], [0, 0]]\r\n","#     y_train = tf.pad(y_train, paddings)\r\n","\r\n","#     return x_train, y_train\r\n","\r\n","\r\n","# def load_tfrecord_dataset(file_pattern, class_file, size=416):\r\n","#     LINE_NUMBER = -1  # TODO: use tf.lookup.TextFileIndex.LINE_NUMBER\r\n","#     class_table = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(\r\n","#         class_file, tf.string, 0, tf.int64, LINE_NUMBER, delimiter=\"\\n\"), -1)\r\n","\r\n","#     files = tf.data.Dataset.list_files(file_pattern)\r\n","#     dataset = files.flat_map(tf.data.TFRecordDataset)\r\n","#     return dataset.map(lambda x: parse_tfrecord(x, class_table, size))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:58.774095Z","iopub.execute_input":"2021-08-14T17:35:58.774429Z","iopub.status.idle":"2021-08-14T17:35:58.781857Z","shell.execute_reply.started":"2021-08-14T17:35:58.774399Z","shell.execute_reply":"2021-08-14T17:35:58.778589Z"},"trusted":true}},{"cell_type":"code","execution_count":11,"source":["# import tensorflow as tf\r\n","\r\n","# @tf.function\r\n","# def transform_targets_for_output(y_true, grid_size, anchor_idxs):\r\n","#     # y_true: (N, boxes, (x1, y1, x2, y2, class, best_anchor))\r\n","#     N = tf.shape(y_true)[0]\r\n","\r\n","#     # y_true_out: (N, grid, grid, anchors, [x1, y1, x2, y2, obj, class])\r\n","#     y_true_out = tf.zeros(\r\n","#         (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\r\n","\r\n","#     anchor_idxs = tf.cast(anchor_idxs, tf.int32)\r\n","\r\n","#     indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\r\n","#     updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\n","#     idx = 0\r\n","#     for i in tf.range(N):\r\n","#         for j in tf.range(tf.shape(y_true)[1]):\r\n","#             if tf.equal(y_true[i][j][2], 0):\r\n","#                 continue\r\n","#             anchor_eq = tf.equal(\r\n","#                 anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))\r\n","\r\n","#             if tf.reduce_any(anchor_eq):\r\n","#                 box = y_true[i][j][0:4]\r\n","#                 box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2\r\n","\r\n","#                 anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\r\n","#                 grid_xy = tf.cast(box_xy // (1/grid_size), tf.int32)\r\n","\r\n","#                 # grid[y][x][anchor] = (tx, ty, bw, bh, obj, class)\r\n","#                 indexes = indexes.write(\r\n","#                     idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\r\n","#                 updates = updates.write(\r\n","#                     idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]])\r\n","#                 idx += 1\r\n","\r\n","#     # tf.print(indexes.stack())\r\n","#     # tf.print(updates.stack())\r\n","\r\n","#     return tf.tensor_scatter_nd_update(\r\n","#         y_true_out, indexes.stack(), updates.stack())\r\n","\r\n","\r\n","# def transform_targets(y_train, anchors, anchor_masks, size):\r\n","#     y_outs = []\r\n","#     grid_size = size // 32\r\n","\r\n","#     # calculate anchor index for true boxes\r\n","#     anchors = tf.cast(anchors, tf.float32)\r\n","#     anchor_area = anchors[..., 0] * anchors[..., 1]\r\n","#     box_wh = y_train[..., 2:4] - y_train[..., 0:2]\r\n","#     box_wh = tf.tile(tf.expand_dims(box_wh, -2),\r\n","#                      (1, 1, tf.shape(anchors)[0], 1))\r\n","#     box_area = box_wh[..., 0] * box_wh[..., 1]\r\n","#     intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * \\\r\n","#         tf.minimum(box_wh[..., 1], anchors[..., 1])\r\n","#     iou = intersection / (box_area + anchor_area - intersection)\r\n","#     anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\r\n","#     anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\r\n","\r\n","#     y_train = tf.concat([y_train, anchor_idx], axis=-1)\r\n","\r\n","#     for anchor_idxs in anchor_masks:\r\n","#         y_outs.append(transform_targets_for_output(\r\n","#             y_train, grid_size, anchor_idxs))\r\n","#         grid_size *= 2\r\n","\r\n","#     return tuple(y_outs)\r\n","\r\n","\r\n","# def transform_images(x_train, size):\r\n","#     x_train = tf.image.resize(x_train, (size, size))\r\n","#     x_train = x_train / 255\r\n","#     return x_train\r\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:58.783854Z","iopub.execute_input":"2021-08-14T17:35:58.784316Z","iopub.status.idle":"2021-08-14T17:35:58.799401Z","shell.execute_reply.started":"2021-08-14T17:35:58.784275Z","shell.execute_reply":"2021-08-14T17:35:58.798233Z"},"trusted":true}},{"cell_type":"code","execution_count":12,"source":["\r\n","def broadcast_iou(box_1, box_2):\r\n","    # box_1: (..., (x1, y1, x2, y2))\r\n","    # box_2: (N, (x1, y1, x2, y2))\r\n","\r\n","    # broadcast boxes\r\n","    box_1 = tf.expand_dims(box_1, -2)\r\n","    box_2 = tf.expand_dims(box_2, 0)\r\n","    # new_shape: (..., N, (x1, y1, x2, y2))\r\n","    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\r\n","    box_1 = tf.broadcast_to(box_1, new_shape)\r\n","    box_2 = tf.broadcast_to(box_2, new_shape)\r\n","\r\n","    int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) -\r\n","                       tf.maximum(box_1[..., 0], box_2[..., 0]), 0)\r\n","    int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) -\r\n","                       tf.maximum(box_1[..., 1], box_2[..., 1]), 0)\r\n","    int_area = int_w * int_h\r\n","    box_1_area = (box_1[..., 2] - box_1[..., 0]) * \\\r\n","        (box_1[..., 3] - box_1[..., 1])\r\n","    box_2_area = (box_2[..., 2] - box_2[..., 0]) * \\\r\n","        (box_2[..., 3] - box_2[..., 1])\r\n","    return int_area / (box_1_area + box_2_area - int_area)\r\n","\r\n","def yolo_boxes(pred, anchors, classes):\r\n","    # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))\r\n","#     print(\"CHECK\")\r\n","    grid_size = tf.shape(pred)[1:3]\r\n","    box_xy, box_wh, objectness, class_probs = tf.split(\r\n","        pred, (2, 2, 1, classes), axis=-1)\r\n","#     print(\"pred\", pred)\r\n","#     print(\"obj\", objectness)\r\n","\r\n","    box_xy = tf.sigmoid(box_xy)\r\n","    objectness = tf.sigmoid(objectness)\r\n","    class_probs = tf.sigmoid(class_probs)\r\n","    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss\r\n","\r\n","    # !!! grid[x][y] == (y, x)\r\n","    grid = _meshgrid(grid_size[1],grid_size[0])\r\n","    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\r\n","\r\n","    box_xy = (box_xy + tf.cast(grid, tf.float32)) / \\\r\n","        tf.cast(grid_size, tf.float32)\r\n","    box_wh = tf.exp(box_wh) * anchors\r\n","\r\n","    box_x1y1 = box_xy - box_wh / 2\r\n","    box_x2y2 = box_xy + box_wh / 2\r\n","    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\r\n","\r\n","    return bbox, objectness, class_probs, pred_box\r\n","\r\n","\r\n","def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\r\n","#     print('CHECK yoloLOSS')\r\n","    def yolo_loss(y_true, y_pred):\r\n","        # 1. transform all pred outputs\r\n","        # y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\r\n","#         print('y_true', y_true)\r\n","#         print(y_true)\r\n","#         print('y_pred, before', y_pred)\r\n","        y_pred = tf.reshape(y_pred, (-1, -1, -1, 3, 5 + N_CLASSES))\r\n","        y_true = tf.reshape(y_true, (-1, -1, -1, 3, 5 + N_CLASSES))\r\n","#         print('y_pred, after', y_pred)\r\n","        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(\r\n","            y_pred, anchors, classes)\r\n","        pred_xy = pred_xywh[..., 0:2]\r\n","        pred_wh = pred_xywh[..., 2:4]\r\n","\r\n","        # 2. transform all true outputs\r\n","        # y_true: (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\r\n","        true_box, true_obj, true_class_idx = tf.split(\r\n","            y_true, (4, 1, 1), axis=-1)\r\n","        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\r\n","        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\r\n","\r\n","        # give higher weights to small boxes\r\n","        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\r\n","\r\n","        # 3. inverting the pred box equations\r\n","        grid_size = tf.shape(y_true)[1]\r\n","        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\r\n","        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\r\n","        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\r\n","            tf.cast(grid, tf.float32)\r\n","        true_wh = tf.math.log(true_wh / anchors)\r\n","        true_wh = tf.where(tf.math.is_inf(true_wh),\r\n","                           tf.zeros_like(true_wh), true_wh)\r\n","\r\n","        # 4. calculate all masks\r\n","        obj_mask = tf.squeeze(true_obj, -1)\r\n","        # ignore false positive when iou is over threshold\r\n","        best_iou = tf.map_fn(\r\n","            lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(\r\n","                x[1], tf.cast(x[2], tf.bool))), axis=-1),\r\n","            (pred_box, true_box, obj_mask),\r\n","            tf.float32)\r\n","        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\r\n","\r\n","        # 5. calculate all losses\r\n","        xy_loss = obj_mask * box_loss_scale * \\\r\n","            tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\r\n","        wh_loss = obj_mask * box_loss_scale * \\\r\n","            tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\r\n","#         print('true_obj', true_obj)\r\n","#         print('pred_obj', pred_obj)\r\n","        obj_loss = binary_crossentropy(true_obj, pred_obj)\r\n","        obj_loss = obj_mask * obj_loss + \\\r\n","            (1 - obj_mask) * ignore_mask * obj_loss\r\n","        # TODO: use binary_crossentropy instead\r\n","        class_loss = obj_mask * sparse_categorical_crossentropy(\r\n","            true_class_idx, pred_class)\r\n","\r\n","        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\r\n","        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\r\n","        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\r\n","        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\r\n","        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\r\n","\r\n","        return xy_loss + wh_loss + obj_loss + class_loss\r\n","    return yolo_loss"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:58.800963Z","iopub.execute_input":"2021-08-14T17:35:58.801660Z","iopub.status.idle":"2021-08-14T17:35:58.840320Z","shell.execute_reply.started":"2021-08-14T17:35:58.801607Z","shell.execute_reply":"2021-08-14T17:35:58.839440Z"},"trusted":true}},{"cell_type":"code","execution_count":13,"source":["n = np.array([[1, 2, 3, 4], [2, 3, 5, 6]])\r\n","print(n.shape)\r\n","n = n.reshape((-1, 2, 2))\r\n","print(n.shape)\r\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 4)\n","(2, 2, 2)\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:58.841530Z","iopub.execute_input":"2021-08-14T17:35:58.842021Z","iopub.status.idle":"2021-08-14T17:35:58.861663Z","shell.execute_reply.started":"2021-08-14T17:35:58.841984Z","shell.execute_reply":"2021-08-14T17:35:58.860385Z"},"trusted":true}},{"cell_type":"code","execution_count":14,"source":["@tf.function\r\n","def transform_targets_for_output(y_true, grid_size, anchor_idxs):\r\n","    # y_true: (N, boxes, (x1, y1, x2, y2, class, best_anchor))\r\n","    N = tf.shape(y_true)[0]\r\n","\r\n","    # y_true_out: (N, grid, grid, anchors, [x1, y1, x2, y2, obj, class])\r\n","    y_true_out = tf.zeros(\r\n","        (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\r\n","\r\n","    anchor_idxs = tf.cast(anchor_idxs, tf.int32)\r\n","\r\n","    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\r\n","    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\n","    idx = 0\r\n","    for i in tf.range(N):\r\n","        for j in tf.range(tf.shape(y_true)[1]):\r\n","            if tf.equal(y_true[i][j][2], 0):\r\n","                continue\r\n","            anchor_eq = tf.equal(\r\n","                anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))\r\n","\r\n","            if tf.reduce_any(anchor_eq):\r\n","                box = y_true[i][j][0:4]\r\n","                box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2\r\n","\r\n","                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\r\n","                grid_xy = tf.cast(box_xy // (1/grid_size), tf.int32)\r\n","\r\n","                # grid[y][x][anchor] = (tx, ty, bw, bh, obj, class)\r\n","                indexes = indexes.write(\r\n","                    idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\r\n","                updates = updates.write(\r\n","                    idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]])\r\n","                idx += 1\r\n","\r\n","    # tf.print(indexes.stack())\r\n","    # tf.print(updates.stack())\r\n","    _y = tf.tensor_scatter_nd_update(\r\n","        y_true_out, indexes.stack(), updates.stack())\r\n","    return tf.reshape(_y, (N, grid_size, grid_size, tf.shape(anchor_idxs)[0] * 6))\r\n","#     return tf.tensor_scatter_nd_update(\r\n","#         y_true_out, indexes.stack(), updates.stack())\r\n","\r\n","\r\n","def transform_targets(y_train, anchors, anchor_masks, size):\r\n","    y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\r\n","#     y_train = np.array(y_train)\r\n","    y_outs = []\r\n","    grid_size = size // 32\r\n","\r\n","    # calculate anchor index for true boxes\r\n","    anchors = tf.cast(anchors, tf.float32)\r\n","    anchor_area = anchors[..., 0] * anchors[..., 1]\r\n","    box_wh = y_train[..., 2:4] - y_train[..., 0:2]\r\n","    box_wh = tf.tile(tf.expand_dims(box_wh, -2),\r\n","                     (1, 1, tf.shape(anchors)[0], 1))\r\n","    box_area = box_wh[..., 0] * box_wh[..., 1]\r\n","    intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * \\\r\n","        tf.minimum(box_wh[..., 1], anchors[..., 1])\r\n","#     print(box_wh)\r\n","#     print(anchors)\r\n","    iou = intersection / (box_area + anchor_area - intersection)\r\n","    anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\r\n","    anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\r\n","\r\n","    y_train = tf.concat([y_train, anchor_idx], axis=-1)\r\n","\r\n","    for anchor_idxs in anchor_masks:\r\n","        y_outs.append(transform_targets_for_output(\r\n","            y_train, grid_size, anchor_idxs))\r\n","        grid_size *= 2\r\n","\r\n","    return tuple(y_outs)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:58.863199Z","iopub.execute_input":"2021-08-14T17:35:58.863597Z","iopub.status.idle":"2021-08-14T17:35:58.893406Z","shell.execute_reply.started":"2021-08-14T17:35:58.863552Z","shell.execute_reply":"2021-08-14T17:35:58.892157Z"},"trusted":true}},{"cell_type":"code","execution_count":15,"source":["from random import shuffle\r\n","\r\n","def parse_boxes(img_infos):\r\n","    N = len (img_infos)\r\n","    # TODO!!! Start from here\r\n","    # y: (N, boxes, (x1, y1, x2, y2, class))\r\n","    # tf.tensor(N, YOLO_MAX_BOXES, 5)\r\n","    # for rect in input_data['Boundingbox']:\r\n","    #    if rect is not np.NaN:\r\n","    #        x0, y0, x1, y1 = rect\r\n","    \r\n","def transform_to_list(row):\r\n","    data = []\r\n","    for i in row:\r\n","        l = i[:]\r\n","        l.append(0.0)\r\n","        data.append(l)\r\n","        \r\n","    if len(row) < YOLO_MAX_BOXES:\r\n","        for i in range(YOLO_MAX_BOXES - len(row)):\r\n","            data += [[0.0, 0.0, 0.0, 0.0, 0.0]]\r\n","            \r\n","    return data\r\n","\r\n","def data_generator(train_df, batch_size=32):\r\n","    print(\"START WORK\")\r\n","    while True:\r\n","        X, y = [], []\r\n","        for ind, i in train_df.sample(n=batch_size).iterrows():\r\n","            img_shape, img = load_img(i['ImageId'])\r\n","            data = transform_to_list(i['Boundingbox'])\r\n","            \r\n","#             if len(data) < YOLO_MAX_BOXES:\r\n","#                 data += [[0, 0, 0, 0, 0] * YOLO_MAX_BOXES - \r\n","            \r\n","            y.append(data)\r\n","#             y.append(transform_targets(data, YOLO_ANCHORS, YOLO_ANCHOR_MASKS, IMAGE_SIZE))\r\n","            X.append(img)\r\n","    \r\n","            \r\n","        print(\"HEREE\")\r\n","        y = transform_targets(y, YOLO_ANCHORS, YOLO_ANCHOR_MASKS, IMAGE_SIZE)\r\n","        \r\n","#         print(\"ISCHEM tshape\")\r\n","#         for t in y:\r\n","#             print(t.shape)\r\n","#         print(y.shape, type(y))\r\n","        yield np.array(X), y"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:58.894971Z","iopub.execute_input":"2021-08-14T17:35:58.895408Z","iopub.status.idle":"2021-08-14T17:35:58.910950Z","shell.execute_reply.started":"2021-08-14T17:35:58.895363Z","shell.execute_reply":"2021-08-14T17:35:58.909559Z"},"trusted":true}},{"cell_type":"code","execution_count":16,"source":["adam = tf.keras.optimizers.Adam(lr=3e-4, decay=1e-6)\n","\n","loss = [YoloLoss(YOLO_ANCHORS[mask], classes=1)\n","        for mask in YOLO_ANCHOR_MASKS]\n","\n","model.compile(optimizer=adam, \n","              loss=loss)\n","# YoloLoss(tf.convert_to_tensor(YOLO_ANCHORS, dtype=tf.float32), classes=1))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:58.912500Z","iopub.execute_input":"2021-08-14T17:35:58.912920Z","iopub.status.idle":"2021-08-14T17:35:58.950118Z","shell.execute_reply.started":"2021-08-14T17:35:58.912876Z","shell.execute_reply":"2021-08-14T17:35:58.949034Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["batch_size = 32\n","\n","gen = data_generator(ships_without_nans, batch_size=batch_size)\n","steps_per_epoch = len(ships_without_nans['ImageId']) / batch_size\n","\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    'hz_detector.hdf5',\n","    monitor='loss',\n","    verbose=1,  \n","    save_best_only=True, \n","    save_weights_only=False,\n","    mode='auto',\n","    save_freq=10\n",")\n","\n","model.fit(gen, \n","          steps_per_epoch=steps_per_epoch,\n","          epochs=1)"],"outputs":[{"output_type":"stream","name":"stdout","text":["START WORK\n","HEREE\n","HEREE\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-14T17:35:58.951785Z","iopub.execute_input":"2021-08-14T17:35:58.952263Z"},"trusted":true}}]}